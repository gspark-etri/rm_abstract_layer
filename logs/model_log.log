2025-12-05T08:04:16,185 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=417410
2025-12-05T08:04:16,186 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-12-05T08:04:16,190 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:04:16,191 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - [PID]417410
2025-12-05T08:04:16,191 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:04:16,191 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:04:16,203 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-12-05T08:04:16,231 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - model_name: gpt2_model, batchSize: 1
2025-12-05T08:04:18,643 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:04:18,643 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:04:18,643 [WARN ] W-9000-gpt2_model_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:04:18,644 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:04:18,644 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:04:18,644 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:04:18,645 [WARN ] W-9000-gpt2_model_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:04:21,516 [INFO ] W-9000-gpt2_model_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:07,929 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9009, pid=420390
2025-12-05T08:14:07,930 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2025-12-05T08:14:07,935 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:07,935 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - [PID]420390
2025-12-05T08:14:07,936 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:07,936 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:07,948 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2025-12-05T08:14:07,976 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - model_name: gpt2_model, batchSize: 1
2025-12-05T08:14:08,003 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9007, pid=420385
2025-12-05T08:14:08,004 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2025-12-05T08:14:08,009 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,010 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - [PID]420385
2025-12-05T08:14:08,010 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,010 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,013 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2025-12-05T08:14:08,024 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9014, pid=420442
2025-12-05T08:14:08,024 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - model_name: gpt2_test, batchSize: 1
2025-12-05T08:14:08,025 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2025-12-05T08:14:08,030 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,030 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - [PID]420442
2025-12-05T08:14:08,030 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,031 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,034 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2025-12-05T08:14:08,045 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - model_name: gpt2_model, batchSize: 1
2025-12-05T08:14:08,050 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9011, pid=420444
2025-12-05T08:14:08,050 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9015, pid=420441
2025-12-05T08:14:08,050 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2025-12-05T08:14:08,050 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2025-12-05T08:14:08,055 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,055 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,055 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - [PID]420444
2025-12-05T08:14:08,056 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - [PID]420441
2025-12-05T08:14:08,056 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,056 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,056 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,056 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,058 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2025-12-05T08:14:08,060 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2025-12-05T08:14:08,061 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9010, pid=420389
2025-12-05T08:14:08,061 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2025-12-05T08:14:08,061 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=420439
2025-12-05T08:14:08,062 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2025-12-05T08:14:08,063 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9006, pid=420445
2025-12-05T08:14:08,064 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2025-12-05T08:14:08,067 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,067 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - [PID]420389
2025-12-05T08:14:08,067 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,067 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,067 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - [PID]420439
2025-12-05T08:14:08,068 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,068 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,068 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,068 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9008, pid=420440
2025-12-05T08:14:08,069 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2025-12-05T08:14:08,074 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,076 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - [PID]420445
2025-12-05T08:14:08,076 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2025-12-05T08:14:08,076 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,076 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - model_name: gpt2_model, batchSize: 1
2025-12-05T08:14:08,076 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,076 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2025-12-05T08:14:08,077 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,076 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - [PID]420440
2025-12-05T08:14:08,077 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,077 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - model_name: gpt2_model, batchSize: 1
2025-12-05T08:14:08,077 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=420387
2025-12-05T08:14:08,078 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,083 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2025-12-05T08:14:08,090 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2025-12-05T08:14:08,083 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9012, pid=420391
2025-12-05T08:14:08,090 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=420386
2025-12-05T08:14:08,090 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2025-12-05T08:14:08,090 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - model_name: gpt2_model, batchSize: 1
2025-12-05T08:14:08,090 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,090 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9013, pid=420443
2025-12-05T08:14:08,090 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2025-12-05T08:14:08,091 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - [PID]420387
2025-12-05T08:14:08,090 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,091 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,091 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,091 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - [PID]420391
2025-12-05T08:14:08,092 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,098 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9005, pid=420384
2025-12-05T08:14:08,098 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=420392
2025-12-05T08:14:08,092 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2025-12-05T08:14:08,103 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,104 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,103 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - model_name: gpt2_test, batchSize: 1
2025-12-05T08:14:08,103 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9004, pid=420388
2025-12-05T08:14:08,104 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,104 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - [PID]420386
2025-12-05T08:14:08,104 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2025-12-05T08:14:08,104 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2025-12-05T08:14:08,104 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2025-12-05T08:14:08,104 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - model_name: gpt2_test, batchSize: 1
2025-12-05T08:14:08,104 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,104 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - [PID]420443
2025-12-05T08:14:08,105 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,106 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,106 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2025-12-05T08:14:08,106 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,106 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2025-12-05T08:14:08,106 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - [PID]420388
2025-12-05T08:14:08,106 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - [PID]420384
2025-12-05T08:14:08,106 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - Successfully loaded /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/ts/configs/metrics.yaml.
2025-12-05T08:14:08,106 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,107 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - [PID]420392
2025-12-05T08:14:08,107 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,107 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,107 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,106 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,108 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - Torch worker started.
2025-12-05T08:14:08,111 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,111 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - Python runtime: 3.11.14
2025-12-05T08:14:08,119 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2025-12-05T08:14:08,120 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - model_name: gpt2_model, batchSize: 1
2025-12-05T08:14:08,120 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2025-12-05T08:14:08,129 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - model_name: gpt2_test, batchSize: 1
2025-12-05T08:14:08,136 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2025-12-05T08:14:08,136 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2025-12-05T08:14:08,137 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2025-12-05T08:14:08,137 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - model_name: gpt2_test, batchSize: 1
2025-12-05T08:14:08,144 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2025-12-05T08:14:08,155 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - model_name: gpt2_model, batchSize: 1
2025-12-05T08:14:08,165 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - model_name: gpt2_model, batchSize: 1
2025-12-05T08:14:08,165 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - model_name: gpt2_test, batchSize: 1
2025-12-05T08:14:08,165 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - model_name: gpt2_test, batchSize: 1
2025-12-05T08:14:08,165 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - model_name: gpt2_test, batchSize: 1
2025-12-05T08:14:11,116 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,116 [WARN ] W-9009-gpt2_model_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,116 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,117 [WARN ] W-9009-gpt2_model_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,117 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,117 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,117 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,218 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,218 [WARN ] W-9014-gpt2_model_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,218 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,218 [WARN ] W-9014-gpt2_model_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,219 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,219 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,219 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,363 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,363 [WARN ] W-9007-gpt2_test_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,364 [WARN ] W-9007-gpt2_test_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,364 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,364 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,364 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,364 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,467 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,468 [WARN ] W-9000-gpt2_test_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,468 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,468 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,468 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,469 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,469 [WARN ] W-9000-gpt2_test_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,506 [WARN ] W-9006-gpt2_test_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,506 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,507 [WARN ] W-9006-gpt2_test_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,507 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,507 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,507 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,507 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,524 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,524 [WARN ] W-9011-gpt2_model_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,524 [WARN ] W-9011-gpt2_model_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,525 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,525 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,525 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,525 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,564 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,564 [WARN ] W-9002-gpt2_test_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,564 [WARN ] W-9002-gpt2_test_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,564 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,565 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,565 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,565 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,569 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,569 [WARN ] W-9010-gpt2_model_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,569 [WARN ] W-9010-gpt2_model_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,569 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,570 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,570 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,570 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,575 [WARN ] W-9008-gpt2_model_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,576 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,576 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,577 [WARN ] W-9008-gpt2_model_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,577 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,577 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,578 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,594 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,594 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,594 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,594 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,594 [WARN ] W-9013-gpt2_model_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,595 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,595 [WARN ] W-9013-gpt2_model_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,617 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,618 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,618 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,618 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,617 [WARN ] W-9003-gpt2_test_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,618 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,618 [WARN ] W-9003-gpt2_test_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,627 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,627 [WARN ] W-9015-gpt2_model_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,627 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,627 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,627 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,627 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,627 [WARN ] W-9015-gpt2_model_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,640 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,640 [WARN ] W-9012-gpt2_model_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,640 [WARN ] W-9012-gpt2_model_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,640 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,640 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,640 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,641 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,651 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,651 [WARN ] W-9005-gpt2_test_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,651 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,651 [WARN ] W-9005-gpt2_test_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,651 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,652 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,652 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,668 [WARN ] W-9004-gpt2_test_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,668 [WARN ] W-9004-gpt2_test_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,668 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,668 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,669 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,669 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,669 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:11,679 [WARN ] W-9001-gpt2_test_1.0-stderr MODEL_LOG - /home/gspark/rm_abstract_layer/.venv/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
2025-12-05T08:14:11,679 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - Enabled tensor cores
2025-12-05T08:14:11,679 [WARN ] W-9001-gpt2_test_1.0-stderr MODEL_LOG -   _C._set_float32_matmul_precision(precision)
2025-12-05T08:14:11,679 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-12-05T08:14:11,679 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-12-05T08:14:11,679 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-12-05T08:14:11,679 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - Loading model: gpt2
2025-12-05T08:14:19,291 [INFO ] W-9007-gpt2_test_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:19,726 [INFO ] W-9006-gpt2_test_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:19,805 [INFO ] W-9000-gpt2_test_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:20,005 [INFO ] W-9004-gpt2_test_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:20,092 [INFO ] W-9002-gpt2_test_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:20,167 [INFO ] W-9001-gpt2_test_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:20,185 [INFO ] W-9014-gpt2_model_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:20,257 [INFO ] W-9009-gpt2_model_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:20,440 [INFO ] W-9005-gpt2_test_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:20,514 [INFO ] W-9003-gpt2_test_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:20,760 [INFO ] W-9011-gpt2_model_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:21,025 [INFO ] W-9013-gpt2_model_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:21,062 [INFO ] W-9012-gpt2_model_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:21,080 [INFO ] W-9015-gpt2_model_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:21,238 [INFO ] W-9010-gpt2_model_1.0-stdout MODEL_LOG - Model loaded successfully
2025-12-05T08:14:21,278 [INFO ] W-9008-gpt2_model_1.0-stdout MODEL_LOG - Model loaded successfully
