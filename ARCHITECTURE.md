# ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

RM Abstract Layerì˜ ì•„í‚¤í…ì²˜ì™€ ì„¤ê³„ ì›ì¹™ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ“ ì „ì²´ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                         â”‚
â”‚  (HuggingFace Transformers, User Code, REST API Client)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  RM Abstract Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Transformersâ”‚  â”‚   Device     â”‚  â”‚   Serving Engine    â”‚ â”‚
â”‚  â”‚    Hook     â”‚  â”‚  Controller  â”‚  â”‚     Factory         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                â”‚                      â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Backend Plugin Registry                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                      â”‚                      â”‚
           â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GPU Backend    â”‚  â”‚   CPU Backend    â”‚  â”‚   NPU Backend    â”‚
â”‚     (vLLM)       â”‚  â”‚   (PyTorch)      â”‚  â”‚   (RBLN)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚                      â”‚
         â–¼                     â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NVIDIA GPU     â”‚  â”‚      CPU         â”‚  â”‚  Rebellions NPU  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© í•µì‹¬ ì»´í¬ë„ŒíŠ¸

### 1. DeviceFlowController

ë””ë°”ì´ìŠ¤ ê´€ë¦¬ ë° ë°±ì—”ë“œ ë¼ìš°íŒ…ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

```python
# src/rm_abstract/core/controller.py

class DeviceFlowController:
    """ë””ë°”ì´ìŠ¤ í”Œë¡œìš° ì»¨íŠ¸ë¡¤ëŸ¬"""
    
    def __init__(self, config: Config):
        self.config = config
        self._backend = None
        self._select_backend()
    
    def _select_backend(self):
        """ì„¤ì •ì— ë”°ë¼ ì ì ˆí•œ ë°±ì—”ë“œ ì„ íƒ"""
        device = self.config.device
        
        if device.startswith("gpu"):
            self._backend = VLLMBackend(...)
        elif device.startswith("rbln"):
            self._backend = RBLNBackend(...)
        else:
            self._backend = CPUBackend(...)
    
    def switch_device(self, device: str):
        """ëŸ°íƒ€ì„ ë””ë°”ì´ìŠ¤ ì „í™˜"""
        self.config.device = device
        self._select_backend()
    
    def prepare_model_with_proxy(self, model):
        """ëª¨ë¸ì„ í”„ë¡ì‹œë¡œ ë˜í•‘"""
        return ModelProxy(model, self._backend)
```

### 2. TransformersHook

HuggingFace Transformersì˜ `from_pretrained` ë©”ì„œë“œë¥¼ í›„í‚¹í•©ë‹ˆë‹¤.

```python
# src/rm_abstract/hooks/transformers_hook.py

def patched_from_pretrained(cls, pretrained_model_name_or_path, *args, **kwargs):
    """from_pretrained í›„í‚¹"""
    # ì›ë³¸ ë©”ì„œë“œ í˜¸ì¶œ
    model = _original_from_pretrained(cls, pretrained_model_name_or_path, *args, **kwargs)
    
    # ì»¨íŠ¸ë¡¤ëŸ¬ê°€ ìˆìœ¼ë©´ í”„ë¡ì‹œë¡œ ë˜í•‘
    if _controller is not None:
        model = _controller.prepare_model_with_proxy(model)
    
    return model
```

### 3. Backend Interface

ëª¨ë“  ë°±ì—”ë“œê°€ êµ¬í˜„í•´ì•¼ í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.

```python
# src/rm_abstract/backends/base.py

class BackendBase(ABC):
    """ë°±ì—”ë“œ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def is_available(self) -> bool:
        """ë°±ì—”ë“œ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        pass
    
    @abstractmethod
    def initialize(self) -> None:
        """ë°±ì—”ë“œ ì´ˆê¸°í™”"""
        pass
    
    @abstractmethod
    def prepare_model(self, model: Any, model_config: Optional[Dict] = None) -> Any:
        """ëª¨ë¸ ì¤€ë¹„ (ì»´íŒŒì¼, ìµœì í™” ë“±)"""
        pass
    
    @abstractmethod
    def execute(self, model: Any, inputs: Any, **kwargs) -> Any:
        """ì¶”ë¡  ì‹¤í–‰"""
        pass
    
    @abstractmethod
    def cleanup(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        pass
```

### 4. ModelProxy

ë°±ì—”ë“œë¡œ ì¶”ë¡  ìš”ì²­ì„ ë¼ìš°íŒ…í•˜ëŠ” í”„ë¡ì‹œì…ë‹ˆë‹¤.

```python
# src/rm_abstract/core/proxy.py

class ModelProxy:
    """ëª¨ë¸ í”„ë¡ì‹œ - ë°±ì—”ë“œë¡œ ìš”ì²­ ë¼ìš°íŒ…"""
    
    def __init__(self, model, backend):
        self._model = model
        self._backend = backend
    
    def generate(self, *args, **kwargs):
        """generate ë©”ì„œë“œ í”„ë¡ì‹œ"""
        return self._backend.execute(
            self._model, 
            args[0] if args else kwargs.get('inputs'),
            _proxy_method="generate",
            **kwargs
        )
    
    def __call__(self, *args, **kwargs):
        """forward ë©”ì„œë“œ í”„ë¡ì‹œ"""
        return self._backend.execute(
            self._model,
            args[0] if args else kwargs.get('inputs'),
            _proxy_method="forward",
            **kwargs
        )
```

---

## ğŸ”Œ ë°±ì—”ë“œ êµ¬í˜„

### GPU Backend (vLLM)

```python
# src/rm_abstract/backends/gpu/vllm_backend.py

class VLLMBackend(BackendBase):
    def __init__(self, device_id: int = 0):
        self.device_id = device_id
        self._llm_engine = None
    
    def is_available(self) -> bool:
        try:
            import vllm
            import torch
            return torch.cuda.is_available()
        except ImportError:
            return False
    
    def prepare_model(self, model, model_config=None):
        from vllm import LLM
        
        model_name = getattr(model.config, '_name_or_path', 'gpt2')
        self._llm_engine = LLM(model=model_name)
        return self._llm_engine
    
    def execute(self, model, inputs, **kwargs):
        from vllm import SamplingParams
        
        sampling_params = SamplingParams(
            max_tokens=kwargs.get('max_new_tokens', 100),
            temperature=kwargs.get('temperature', 1.0),
        )
        
        outputs = self._llm_engine.generate(prompts, sampling_params)
        return self._convert_to_hf_format(outputs)
```

### CPU Backend (PyTorch)

```python
# src/rm_abstract/backends/cpu/cpu_backend.py

class CPUBackend(BackendBase):
    def is_available(self) -> bool:
        try:
            import torch
            return True
        except ImportError:
            return False
    
    def prepare_model(self, model, model_config=None):
        model.to('cpu')
        model.eval()
        return model
    
    def execute(self, model, inputs, **kwargs):
        import torch
        
        with torch.no_grad():
            if kwargs.get('_proxy_method') == 'generate':
                return model.generate(inputs, **kwargs)
            else:
                return model(inputs)
```

### NPU Backend (RBLN)

```python
# src/rm_abstract/backends/npu/plugins/rebellions.py

class RBLNBackend(NPUBackendBase):
    def __init__(self, device_id: int = 0, mode: str = "auto"):
        self.device_id = device_id
        self.mode = self._detect_mode(mode)
    
    def _detect_mode(self, mode: str) -> str:
        if mode == "auto":
            # vLLM-RBLN ìš°ì„ 
            try:
                import vllm
                return "vllm"
            except ImportError:
                return "optimum"
        return mode
    
    def prepare_model(self, model, model_config=None):
        if self.mode == "vllm":
            return self._prepare_vllm(model, model_config)
        else:
            return self._prepare_optimum(model, model_config)
```

---

## ğŸš€ ì„œë¹™ ì—”ì§„ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ServingEngineFactory                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                      â”‚                      â”‚
           â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VLLMEngine     â”‚  â”‚  TritonEngine    â”‚  â”‚ TorchServeEngine â”‚
â”‚  - load_model()  â”‚  â”‚  - load_model()  â”‚  â”‚  - load_model()  â”‚
â”‚  - infer()       â”‚  â”‚  - infer()       â”‚  â”‚  - infer()       â”‚
â”‚  - start()       â”‚  â”‚  - start()       â”‚  â”‚  - start()       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
# src/rm_abstract/serving/base.py

class ServingEngine(ABC):
    """ì„œë¹™ ì—”ì§„ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    @property
    @abstractmethod
    def name(self) -> str:
        pass
    
    @abstractmethod
    def load_model(self, model_name: str, **kwargs) -> Any:
        pass
    
    @abstractmethod
    def infer(self, prompt: str, **kwargs) -> str:
        pass
```

---

## ğŸ“Š í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ

### í”ŒëŸ¬ê·¸ì¸ ë“±ë¡

```python
# src/rm_abstract/backends/auto_register.py

def auto_register_backends():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—”ë“œ ìë™ ë“±ë¡"""
    
    # GPU ë°±ì—”ë“œ
    try:
        from .gpu.vllm_backend import VLLMBackend
        registry.register(create_backend_plugin(
            backend_class=VLLMBackend,
            name="gpu",
            priority=PluginPriority.HIGH,
        ))
    except ImportError:
        pass
    
    # CPU ë°±ì—”ë“œ
    try:
        from .cpu.cpu_backend import CPUBackend
        registry.register(create_backend_plugin(
            backend_class=CPUBackend,
            name="cpu",
            priority=PluginPriority.LOW,
        ))
    except ImportError:
        pass
```

### í”ŒëŸ¬ê·¸ì¸ ìš°ì„ ìˆœìœ„

```
NPU (HIGHEST) > GPU (HIGH) > PIM (MEDIUM) > CPU (LOW) > Remote (LOWEST)
```

---

## ğŸ”„ ë°ì´í„° íë¦„

### ì¶”ë¡  ìš”ì²­ íë¦„

```
1. User: model.generate(inputs)
         â”‚
         â–¼
2. ModelProxy.generate(inputs)
         â”‚
         â–¼
3. Backend.execute(model, inputs)
         â”‚
         â–¼
4. Hardware (GPU/CPU/NPU)
         â”‚
         â–¼
5. Backend._convert_to_hf_format(outputs)
         â”‚
         â–¼
6. Return to User
```

### ë””ë°”ì´ìŠ¤ ì „í™˜ íë¦„

```
1. User: rm_abstract.switch_device("cpu")
         â”‚
         â–¼
2. Controller.switch_device("cpu")
         â”‚
         â–¼
3. Old Backend.cleanup()
         â”‚
         â–¼
4. New Backend = CPUBackend()
         â”‚
         â–¼
5. New Backend.initialize()
         â”‚
         â–¼
6. Update Controller._backend
```

---

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
src/rm_abstract/
â”œâ”€â”€ __init__.py           # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
â”œâ”€â”€ api/                  # REST API
â”‚   â”œâ”€â”€ server.py         # FastAPI ì„œë²„
â”‚   â””â”€â”€ models.py         # Pydantic ëª¨ë¸
â”œâ”€â”€ backends/             # ë°±ì—”ë“œ êµ¬í˜„
â”‚   â”œâ”€â”€ base.py           # ë°±ì—”ë“œ ê¸°ë³¸ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ auto_register.py  # ìë™ ë“±ë¡
â”‚   â”œâ”€â”€ cpu/              # CPU ë°±ì—”ë“œ
â”‚   â”œâ”€â”€ gpu/              # GPU ë°±ì—”ë“œ
â”‚   â””â”€â”€ npu/              # NPU ë°±ì—”ë“œ
â”œâ”€â”€ serving/              # ì„œë¹™ ì—”ì§„
â”‚   â”œâ”€â”€ base.py           # ì„œë¹™ ì—”ì§„ ê¸°ë³¸
â”‚   â”œâ”€â”€ vllm_engine.py    # vLLM
â”‚   â”œâ”€â”€ triton_engine.py  # Triton
â”‚   â””â”€â”€ torchserve_engine.py # TorchServe
â”œâ”€â”€ core/                 # ì½”ì–´ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ controller.py     # ë””ë°”ì´ìŠ¤ ì»¨íŠ¸ë¡¤ëŸ¬
â”‚   â”œâ”€â”€ config.py         # ì„¤ì •
â”‚   â””â”€â”€ proxy.py          # ëª¨ë¸ í”„ë¡ì‹œ
â”œâ”€â”€ hooks/                # í›…
â”‚   â””â”€â”€ transformers_hook.py
â”œâ”€â”€ system_info.py        # ì‹œìŠ¤í…œ ì •ë³´
â”œâ”€â”€ system_validator.py   # ì‹œìŠ¤í…œ ê²€ì¦
â””â”€â”€ installer.py          # ì„¤ì¹˜ í—¬í¼
```

---

## ğŸ¯ ì„¤ê³„ ì›ì¹™

1. **ìµœì†Œ ì¹¨ìŠµì„±**: ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ìµœì†Œí™”
2. **íˆ¬ëª…ì„±**: ë°±ì—”ë“œ ì„¸ë¶€ì‚¬í•­ ì¶”ìƒí™”
3. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ë°±ì—”ë“œ ì‰½ê²Œ ì¶”ê°€
4. **ìœ ì—°ì„±**: ëŸ°íƒ€ì„ ë””ë°”ì´ìŠ¤ ì „í™˜
5. **í˜¸í™˜ì„±**: OpenAI API í˜¸í™˜

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [INSTALL.md](INSTALL.md) - ì„¤ì¹˜ ê°€ì´ë“œ
- [API.md](API.md) - REST API ë ˆí¼ëŸ°ìŠ¤
- [CONTRIBUTING.md](CONTRIBUTING.md) - ê°œë°œ ê°€ì´ë“œ

