# REST API ë ˆí¼ëŸ°ìŠ¤

RM Abstract Layer REST API ë¬¸ì„œì…ë‹ˆë‹¤. OpenAI APIì™€ í˜¸í™˜ë©ë‹ˆë‹¤.

---

## ğŸš€ ì„œë²„ ì‹œì‘

```bash
# ê¸°ë³¸ ì‹¤í–‰
python -m rm_abstract.api

# í¬íŠ¸ ì§€ì •
python -m rm_abstract.api --port 8000

# Uvicorn ì§ì ‘ ì‚¬ìš©
uvicorn rm_abstract.api.server:app --host 0.0.0.0 --port 8000 --reload
```

**ì„œë²„ ì •ë³´:**
- API ë¬¸ì„œ: http://localhost:8000/docs
- OpenAPI ìŠ¤í™: http://localhost:8000/openapi.json

---

## ğŸ“‹ ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡

| Method | Endpoint | ì„¤ëª… |
|--------|----------|------|
| GET | `/` | ì„œë²„ ì •ë³´ |
| GET | `/health` | í—¬ìŠ¤ ì²´í¬ |
| GET | `/v1/models` | ëª¨ë¸ ëª©ë¡ |
| GET | `/v1/models/{model_id}` | ëª¨ë¸ ì •ë³´ |
| POST | `/v1/completions` | í…ìŠ¤íŠ¸ ìƒì„± |
| POST | `/v1/chat/completions` | ì±„íŒ… ìƒì„± |
| GET | `/v1/devices/status` | ì‹œìŠ¤í…œ ìƒíƒœ |
| POST | `/v1/devices/switch` | ë””ë°”ì´ìŠ¤ ì „í™˜ |

---

## ğŸ”§ API ìƒì„¸

### í—¬ìŠ¤ ì²´í¬

```http
GET /health
```

**ì‘ë‹µ:**
```json
{
  "status": "ok",
  "initialized": true
}
```

---

### ëª¨ë¸ ëª©ë¡

```http
GET /v1/models
```

**ì‘ë‹µ:**
```json
{
  "object": "list",
  "data": [
    {
      "id": "gpt2",
      "object": "model",
      "created": 1234567890,
      "owned_by": "rm-abstract"
    }
  ]
}
```

---

### í…ìŠ¤íŠ¸ ìƒì„± (Completions)

```http
POST /v1/completions
Content-Type: application/json
```

**ìš”ì²­:**
```json
{
  "model": "gpt2",
  "prompt": "Hello, I am",
  "max_tokens": 50,
  "temperature": 0.7,
  "top_p": 0.9,
  "n": 1,
  "stop": ["\n"]
}
```

**íŒŒë¼ë¯¸í„°:**

| íŒŒë¼ë¯¸í„° | íƒ€ì… | ê¸°ë³¸ê°’ | ì„¤ëª… |
|----------|------|--------|------|
| model | string | í•„ìˆ˜ | ëª¨ë¸ ID |
| prompt | string/array | í•„ìˆ˜ | ì…ë ¥ í”„ë¡¬í”„íŠ¸ |
| max_tokens | integer | 100 | ìµœëŒ€ ìƒì„± í† í° ìˆ˜ |
| temperature | float | 1.0 | ìƒ˜í”Œë§ ì˜¨ë„ (0-2) |
| top_p | float | 1.0 | Nucleus ìƒ˜í”Œë§ (0-1) |
| n | integer | 1 | ìƒì„±í•  ì‘ë‹µ ìˆ˜ |
| stop | string/array | null | ì¤‘ì§€ ì‹œí€€ìŠ¤ |

**ì‘ë‹µ:**
```json
{
  "id": "cmpl-1234567890",
  "object": "text_completion",
  "created": 1234567890,
  "model": "gpt2",
  "choices": [
    {
      "text": " a language model trained by...",
      "index": 0,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 4,
    "completion_tokens": 50,
    "total_tokens": 54
  }
}
```

---

### ì±„íŒ… ìƒì„± (Chat Completions)

```http
POST /v1/chat/completions
Content-Type: application/json
```

**ìš”ì²­:**
```json
{
  "model": "gpt2",
  "messages": [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "What is AI?"}
  ],
  "max_tokens": 100,
  "temperature": 0.7
}
```

**ë©”ì‹œì§€ ì—­í• :**

| ì—­í•  | ì„¤ëª… |
|------|------|
| system | ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ |
| user | ì‚¬ìš©ì ë©”ì‹œì§€ |
| assistant | ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ |

**ì‘ë‹µ:**
```json
{
  "id": "chatcmpl-1234567890",
  "object": "chat.completion",
  "created": 1234567890,
  "model": "gpt2",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "AI, or Artificial Intelligence, is..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 100,
    "total_tokens": 120
  }
}
```

---

### ì‹œìŠ¤í…œ ìƒíƒœ

```http
GET /v1/devices/status
```

**ì‘ë‹µ:**
```json
{
  "status": "ok",
  "current_device": "gpu:0",
  "current_backend": "VLLMBackend",
  "available_devices": [
    {
      "device_type": "gpu",
      "device_id": 0,
      "name": "NVIDIA GeForce RTX 3090",
      "vendor": "NVIDIA",
      "memory_total_gb": 24.0,
      "memory_free_gb": 20.0
    },
    {
      "device_type": "cpu",
      "device_id": 0,
      "name": "x86_64",
      "memory_total_gb": 128.0,
      "memory_free_gb": 100.0
    }
  ],
  "available_backends": [
    {
      "name": "gpu",
      "display_name": "vLLM GPU Backend",
      "available": true,
      "device_type": "GPU",
      "version": "0.12.0"
    },
    {
      "name": "cpu",
      "display_name": "PyTorch CPU Backend",
      "available": true,
      "device_type": "CPU"
    }
  ]
}
```

---

### ë””ë°”ì´ìŠ¤ ì „í™˜

```http
POST /v1/devices/switch
Content-Type: application/json
```

**ìš”ì²­:**
```json
{
  "device": "cpu"
}
```

**ë””ë°”ì´ìŠ¤ ì˜µì…˜:**

| ê°’ | ì„¤ëª… |
|----|------|
| `gpu:0` | GPU 0ë²ˆ |
| `gpu:1` | GPU 1ë²ˆ |
| `cpu` | CPU |
| `rbln:0` | Rebellions NPU 0ë²ˆ |
| `auto` | ìë™ ì„ íƒ |

**ì‘ë‹µ:**
```json
{
  "success": true,
  "previous_device": "gpu:0",
  "current_device": "cpu:0",
  "message": "Switched from gpu:0 to cpu:0"
}
```

---

## ğŸ’» ì‚¬ìš© ì˜ˆì œ

### cURL

```bash
# í…ìŠ¤íŠ¸ ìƒì„±
curl -X POST http://localhost:8000/v1/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt2",
    "prompt": "Hello",
    "max_tokens": 50
  }'

# ì±„íŒ…
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt2",
    "messages": [{"role": "user", "content": "Hi!"}]
  }'

# ë””ë°”ì´ìŠ¤ ì „í™˜
curl -X POST http://localhost:8000/v1/devices/switch \
  -H "Content-Type: application/json" \
  -d '{"device": "cpu"}'
```

### Python (requests)

```python
import requests

BASE_URL = "http://localhost:8000"

# í…ìŠ¤íŠ¸ ìƒì„±
response = requests.post(
    f"{BASE_URL}/v1/completions",
    json={
        "model": "gpt2",
        "prompt": "The future of AI is",
        "max_tokens": 50,
        "temperature": 0.7,
    }
)
print(response.json()["choices"][0]["text"])

# ì±„íŒ…
response = requests.post(
    f"{BASE_URL}/v1/chat/completions",
    json={
        "model": "gpt2",
        "messages": [
            {"role": "system", "content": "You are helpful."},
            {"role": "user", "content": "What is Python?"},
        ],
    }
)
print(response.json()["choices"][0]["message"]["content"])
```

### Python (OpenAI SDK)

```python
from openai import OpenAI

# RM Abstract API ì„œë²„ ì‚¬ìš©
client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed",  # API í‚¤ ë¶ˆí•„ìš”
)

# í…ìŠ¤íŠ¸ ìƒì„±
response = client.completions.create(
    model="gpt2",
    prompt="Hello, I am",
    max_tokens=50,
)
print(response.choices[0].text)

# ì±„íŒ…
response = client.chat.completions.create(
    model="gpt2",
    messages=[
        {"role": "user", "content": "Hello!"}
    ],
)
print(response.choices[0].message.content)
```

---

## âŒ ì—ëŸ¬ ì‘ë‹µ

```json
{
  "error": {
    "message": "Model not found: invalid-model",
    "type": "invalid_request_error",
    "param": "model",
    "code": "404"
  }
}
```

**ì—ëŸ¬ ì½”ë“œ:**

| ì½”ë“œ | ì„¤ëª… |
|------|------|
| 400 | ì˜ëª»ëœ ìš”ì²­ |
| 404 | ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ |
| 500 | ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ |

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [QUICKSTART.md](QUICKSTART.md) - ë¹ ë¥¸ ì‹œì‘
- [INSTALL.md](INSTALL.md) - ì„¤ì¹˜ ê°€ì´ë“œ

