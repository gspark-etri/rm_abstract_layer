# ì„¤ì¹˜ ê°€ì´ë“œ

RM Abstract Layer ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì • ê°€ì´ë“œì…ë‹ˆë‹¤.

---

## ğŸ“‹ ìš”êµ¬ì‚¬í•­

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **Python**: 3.9 ì´ìƒ
- **OS**: Linux (Ubuntu 20.04+), macOS
- **ë©”ëª¨ë¦¬**: ìµœì†Œ 8GB RAM (16GB ê¶Œì¥)

### í•˜ë“œì›¨ì–´ë³„ ìš”êµ¬ì‚¬í•­

| í•˜ë“œì›¨ì–´ | ìš”êµ¬ì‚¬í•­ |
|----------|----------|
| GPU | NVIDIA GPU (CUDA 11.8+), 8GB+ VRAM |
| NPU (RBLN) | Rebellions ATOM + RBLN SDK |
| CPU | x86_64 ë˜ëŠ” ARM64 |

---

## ğŸ ê°€ìƒí™˜ê²½ ì„¤ì •

íŒ¨í‚¤ì§€ ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ **ê°€ìƒí™˜ê²½ ì‚¬ìš©ì„ ê°•ë ¥íˆ ê¶Œì¥**í•©ë‹ˆë‹¤.

### ë°©ë²• 1: uv (ê¶Œì¥) âš¡

[uv](https://github.com/astral-sh/uv)ëŠ” Rustë¡œ ì‘ì„±ëœ ì´ˆê³ ì† Python íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €ì…ë‹ˆë‹¤.

**ì¥ì :**
- pipë³´ë‹¤ 10-100ë°° ë¹ ë¥¸ ì„¤ì¹˜ ì†ë„
- ìë™ Python ë²„ì „ ê´€ë¦¬
- ë¹ŒíŠ¸ì¸ ê°€ìƒí™˜ê²½ ì§€ì›
- pip/venv ì™„ë²½ í˜¸í™˜

```bash
# uv ì„¤ì¹˜
curl -LsSf https://astral.sh/uv/install.sh | sh

# í„°ë¯¸ë„ ì¬ì‹œì‘ ë˜ëŠ”
source ~/.bashrc  # ë˜ëŠ” ~/.zshrc

# ê°€ìƒí™˜ê²½ ìƒì„±
uv venv .venv

# í™œì„±í™”
source .venv/bin/activate  # Linux/macOS
.venv\Scripts\activate      # Windows

# íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì´ˆê³ ì†!)
uv pip install -e ".[all]"
```

### ë°©ë²• 2: venv (Python ê¸°ë³¸)

Python 3.3+ ë‚´ì¥ ê°€ìƒí™˜ê²½ ë„êµ¬ì…ë‹ˆë‹¤.

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv .venv

# í™œì„±í™”
source .venv/bin/activate  # Linux/macOS
.venv\Scripts\activate      # Windows

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -e ".[all]"
```

### ë°©ë²• 3: conda

Anaconda/Miniconda ì‚¬ìš©ìë¥¼ ìœ„í•œ ë°©ë²•ì…ë‹ˆë‹¤.

```bash
# í™˜ê²½ ìƒì„±
conda create -n rm_abstract python=3.10

# í™œì„±í™”
conda activate rm_abstract

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -e ".[all]"
```

### ê°€ìƒí™˜ê²½ ë¹„í™œì„±í™”

```bash
deactivate  # venv, uv
conda deactivate  # conda
```

---

## ğŸš€ ë¹ ë¥¸ ì„¤ì¹˜

### ê¸°ë³¸ ì„¤ì¹˜

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í›„
pip install -e .

# GPU ì§€ì›
pip install -e ".[gpu]"

# ì „ì²´ ì„¤ì¹˜
pip install -e ".[all]"
```

### uvë¡œ ë¹ ë¥¸ ì„¤ì¹˜ (ê¶Œì¥)

```bash
# í•œ ë²ˆì— ì„¤ì • (uv ì„¤ì¹˜ â†’ ê°€ìƒí™˜ê²½ â†’ íŒ¨í‚¤ì§€)
curl -LsSf https://astral.sh/uv/install.sh | sh
source ~/.bashrc
uv venv .venv && source .venv/bin/activate
uv pip install -e ".[all]"
```

---

## ğŸ“¦ ì»´í¬ë„ŒíŠ¸ë³„ ì„¤ì¹˜

### ì„¤ì¹˜ ìƒíƒœ í™•ì¸

```bash
python -m rm_abstract.installer
```

ì¶œë ¥ ì˜ˆì‹œ:
```
============================================================
  RM Abstract Layer - Installation Guide
============================================================

Components:
  âœ“ Base: Core functionality
  âœ“ GPU (vLLM): High-performance GPU inference
  âœ“ Triton: Multi-model serving
  âœ“ TorchServe: PyTorch native serving

System Dependencies:
  âœ— Java 11: Required for TorchServe server
  âœ“ Docker: Required for Triton server
```

### Python íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# ì»´í¬ë„ŒíŠ¸ë³„ ì„¤ì¹˜
python -m rm_abstract.installer base        # ê¸°ë³¸
python -m rm_abstract.installer gpu         # GPU/vLLM
python -m rm_abstract.installer triton      # Triton
python -m rm_abstract.installer torchserve  # TorchServe
python -m rm_abstract.installer all         # ì „ì²´
```

### ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
./scripts/install_deps.sh java              # Java (TorchServeìš©)
./scripts/install_deps.sh docker            # Docker (Tritonìš©)
./scripts/install_deps.sh nvidia-docker     # NVIDIA Container Toolkit
```

#### ìˆ˜ë™ ì„¤ì¹˜

**Java 11 (TorchServeìš©)**
```bash
# Ubuntu/Debian
sudo apt update && sudo apt install -y openjdk-11-jdk

# RHEL/CentOS
sudo yum install -y java-11-openjdk

# macOS
brew install openjdk@11
```

**Docker (Tritonìš©)**
```bash
# Ubuntu/Debian
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER

# NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt update && sudo apt install -y nvidia-container-toolkit
sudo systemctl restart docker
```

---

## ğŸ”§ ìƒì„¸ ì„¤ì¹˜

### GPU (vLLM) ì„¤ì¹˜

```bash
# requirements íŒŒì¼ ì‚¬ìš©
pip install -r requirements/gpu.txt

# ë˜ëŠ” ì§ì ‘ ì„¤ì¹˜
pip install vllm>=0.4.0 torch>=2.0.0
```

**í™•ì¸:**
```python
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"GPU count: {torch.cuda.device_count()}")

import vllm
print(f"vLLM version: {vllm.__version__}")
```

### Triton ì„¤ì¹˜

```bash
# í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜
pip install -r requirements/triton.txt

# Docker ì´ë¯¸ì§€ (ì„œë²„)
docker pull nvcr.io/nvidia/tritonserver:24.01-py3
```

**ì„œë²„ ì‹œì‘:**
```bash
# Docker Compose ì‚¬ìš©
docker-compose -f docker/docker-compose.yml up triton

# ë˜ëŠ” ì§ì ‘ ì‹¤í–‰
docker run --gpus=1 --rm -p8000:8000 -p8001:8001 \
  -v /path/to/models:/models \
  nvcr.io/nvidia/tritonserver:24.01-py3 \
  tritonserver --model-repository=/models
```

### TorchServe ì„¤ì¹˜

```bash
# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements/torchserve.txt

# Java ì„¤ì¹˜ í•„ìš”
sudo apt install openjdk-11-jdk
```

**ì„œë²„ ì‹œì‘:**
```bash
torchserve --start \
  --model-store ~/.rm_abstract/torchserve_models \
  --models all
```

### Rebellions NPU ì„¤ì¹˜

```bash
# RBLN SDK ì„¤ì¹˜ (í•˜ë“œì›¨ì–´ í•„ìš”)
pip install rebel-sdk

# ì„ íƒ 1: vLLM-RBLN (ê³ ì„±ëŠ¥)
pip install vllm-rbln

# ì„ íƒ 2: Optimum-RBLN (HuggingFace í†µí•©)
pip install optimum-rbln
```

**ì°¸ê³ :** https://docs.rbln.ai/latest/

---

## âœ… ì„¤ì¹˜ í™•ì¸

### ì‹œìŠ¤í…œ ê²€ì¦

```bash
# ì „ì²´ ê²€ì¦ (ì‹¤ì œ ì¶”ë¡  í…ŒìŠ¤íŠ¸ í¬í•¨)
python -m rm_abstract.system_validator

# ë¹ ë¥¸ ê²€ì¦ (ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì œì™¸)
python -m rm_abstract.system_validator --quick
```

### Pythonì—ì„œ í™•ì¸

```python
import rm_abstract

# ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
rm_abstract.print_system_info()

# ê²€ì¦ ì‹¤í–‰
rm_abstract.print_validation_report()

# ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—”ë“œ í™•ì¸
backends = rm_abstract.get_available_backends()
print(backends)
```

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# pytest í…ŒìŠ¤íŠ¸
pytest tests/test_core.py -v
pytest tests/test_api.py -v
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# ë‹¤ë¥¸ GPU ì‚¬ìš©
CUDA_VISIBLE_DEVICES=1 python your_script.py

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¤„ì´ê¸°
export VLLM_GPU_MEMORY_UTILIZATION=0.5
```

### vLLM ë©€í‹°í”„ë¡œì„¸ì‹± ì˜¤ë¥˜

```python
# ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ì¶”ê°€
if __name__ == "__main__":
    # ì½”ë“œë¥¼ ì—¬ê¸°ì—
    pass
```

### Triton ì„œë²„ ì—°ê²° ì‹¤íŒ¨

```bash
# ì„œë²„ ìƒíƒœ í™•ì¸
curl http://localhost:8000/v2/health/ready

# ë¡œê·¸ í™•ì¸
docker logs rm_triton
```

### TorchServe Java ì˜¤ë¥˜

```bash
# Java ë²„ì „ í™•ì¸
java -version

# JAVA_HOME ì„¤ì •
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
```

---

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

ì„¤ì¹˜ í›„ ìƒì„±ë˜ëŠ” ë””ë ‰í† ë¦¬:

```
~/.rm_abstract/
â”œâ”€â”€ cache/              # ì»´íŒŒì¼ ìºì‹œ
â”œâ”€â”€ torchserve_models/  # TorchServe ëª¨ë¸ ì €ì¥ì†Œ
â””â”€â”€ logs/               # ë¡œê·¸ íŒŒì¼
```

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [QUICKSTART.md](QUICKSTART.md) - ë¹ ë¥¸ ì‹œì‘ ì˜ˆì œ
- [ARCHITECTURE.md](ARCHITECTURE.md) - ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
- [API.md](API.md) - REST API ë¬¸ì„œ
