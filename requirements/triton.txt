# Triton Inference Server requirements
-r base.txt

# Triton client libraries
tritonclient[all]>=2.40.0

# For model conversion
onnx>=1.14.0
onnxruntime>=1.15.0

